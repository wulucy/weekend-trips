{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_best_flights(url):\n",
    "    \n",
    "    # Run browser - need to run full browser to get JavaScript elements\n",
    "    driver = webdriver.Chrome('/Users/lucy/Documents/Research/chromedriver')\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait until page is loaded\n",
    "    try:\n",
    "        WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.ID,'gws-flights-results__best_flights_heading')))\n",
    "    except TimeoutException:\n",
    "        print(\"Loading took too much time!\")\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "    \n",
    "    # Get list of best flights\n",
    "    best_flight_heading = soup.find('span', {'id': 'gws-flights-results__best_flights_heading'})\n",
    "    best_flights_list = best_flight_heading.find_next('ol', {'class': 'gws-flights-results__result-list'})\n",
    "    best_flights = best_flights_list.find_all('li', {'class': 'gws-flights-results__result-item'})\n",
    "    \n",
    "    # Iterate through each flight to collect time, duration, price, and type (round trip or not)\n",
    "    flight_data = pd.DataFrame(columns=['time', 'duration', 'price'])\n",
    "    for flight in best_flights:\n",
    "        times = flight.find('div', {'class': 'gws-flights-results__times'}).text\n",
    "        durations = flight.find('div', {'class': 'gws-flights-results__duration'}).text\n",
    "        prices = flight.find('div', {'class': 'gws-flights-results__price'}).text\n",
    "        res = pd.DataFrame({'time': [times], 'duration': [durations], 'price': [prices]})\n",
    "        flight_data = flight_data.append(res)\n",
    "        \n",
    "    return flight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_flights(url):\n",
    "    \n",
    "    # Run browser - need to run full browser to get JavaScript elements\n",
    "    driver = webdriver.Chrome('/Users/lucy/Documents/Research/chromedriver')\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait until page is loaded\n",
    "    try:\n",
    "        WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.ID,'gws-flights-results__best_flights_heading')))\n",
    "    except TimeoutException:\n",
    "        print(\"Loading took too much time!\")\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "    \n",
    "    # Get lists of best flights\n",
    "    flights_lists = soup.find_all('ol', {'class': 'gws-flights-results__result-list'})\n",
    "    flight_data = pd.DataFrame(columns=['time', 'duration', 'price'])\n",
    "    for flights_list in flights_lists:\n",
    "        best_flights = flights_list.find_all('li', {'class': 'gws-flights-results__result-item'})\n",
    "\n",
    "        # Iterate through each flight to collect time, duration, price, and type (round trip or not)\n",
    "        for flight in best_flights:\n",
    "            times = flight.find('div', {'class': 'gws-flights-results__times'}).text\n",
    "            durations = flight.find('div', {'class': 'gws-flights-results__duration'}).text\n",
    "            prices = flight.find('div', {'class': 'gws-flights-results__price'}).text\n",
    "            res = pd.DataFrame({'time': [times], 'duration': [durations], 'price': [prices]})\n",
    "            flight_data = flight_data.append(res)\n",
    "        \n",
    "    return flight_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 0: 10/17-10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=BOS./m/0dclg.2019-10-17;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-17-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'Boston'\n",
    "flights.to_csv('data/boston/flights_10-17-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0dclg.BOS.2019-10-20;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-20-2019'\n",
    "flights['origination'] = 'Boston'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/boston/flights_10-20-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 1: 10/24-10/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=BOS./m/0dclg.2019-10-24;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-24-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'Boston'\n",
    "flights.to_csv('data/boston/flights_10-24-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=BOS./m/0dclg.2019-10-27;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-27-2019'\n",
    "flights['origination'] = 'Boston'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/boston/flights_10-27-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 2: 10/31-11/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0dclg.BOS.2019-10-31;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-31-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'Boston'\n",
    "flights.to_csv('data/boston/flights_10-31-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=BOS./m/0dclg.2019-11-03;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '11-03-2019'\n",
    "flights['origination'] = 'Boston'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/boston/flights_11-03-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 0: 10/17-10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0dclg./m/02_286.2019-10-17;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-17-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'NYC'\n",
    "flights.to_csv('data/nyc/flights_10-17-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/02_286./m/0dclg.2019-10-20;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-20-2019'\n",
    "flights['origination'] = 'NYC'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/nyc/flights_10-20-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 1: 10/24-10/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0dclg./m/02_286.2019-10-24;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-24-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'NYC'\n",
    "flights.to_csv('data/nyc/flights_10-24-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/02_286./m/0dclg.2019-10-27;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-27-2019'\n",
    "flights['origination'] = 'NYC'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/nyc/flights_10-27-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 2: 10/31-11/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0dclg./m/02_286.2019-10-31;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-31-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'NYC'\n",
    "flights.to_csv('data/nyc/flights_10-31-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/02_286./m/0dclg.2019-11-03;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '11-03-2019'\n",
    "flights['origination'] = 'NYC'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/nyc/flights_11-03-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 0: 10/17-10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0dclg./m/0rh6k.2019-10-17;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-17-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'DC'\n",
    "flights.to_csv('data/dc/flights_10-17-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0rh6k./m/0dclg.2019-10-20;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-20-2019'\n",
    "flights['origination'] = 'DC'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/dc/flights_10-20-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 1: 10/24-10/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0dclg./m/0rh6k.2019-10-24;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-24-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'DC'\n",
    "flights.to_csv('data/dc/flights_10-24-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0rh6k./m/0dclg.2019-10-27;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-27-2019'\n",
    "flights['origination'] = 'DC'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/dc/flights_10-27-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 2: 10/31-11/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0dclg./m/0rh6k.2019-10-31;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '10-31-2019'\n",
    "flights['origination'] = 'Philadelphia'\n",
    "flights['destination'] = 'DC'\n",
    "flights.to_csv('data/dc/flights_10-31-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = scrape_flights('https://www.google.com/flights#flt=/m/0rh6k./m/0dclg.2019-11-03;c:USD;e:1;sd:1;t:f;tt:o')\n",
    "flights['date'] = '11-03-2019'\n",
    "flights['origination'] = 'DC'\n",
    "flights['destination'] = 'Philadelphia'\n",
    "flights.to_csv('data/dc/flights_11-03-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page is ready!\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.google.com/flights#flt=/m/0rh6k./m/0dclg.2019-10-27;c:USD;e:1;sd:1;t:f;tt:o'\n",
    "\n",
    "driver = webdriver.Chrome('/Users/lucy/Documents/Research/chromedriver')\n",
    "driver.get(url)\n",
    "delay = 3 # seconds\n",
    "\n",
    "try:\n",
    "    myElem = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.ID,\n",
    "                                                                                'gws-flights-results__best_flights_heading')))\n",
    "except TimeoutException:\n",
    "    print(\"Loading took too much time!\")\n",
    "    \n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "# Get list of best flights\n",
    "best_flight_heading = soup.find('span', {'id': 'gws-flights-results__best_flights_heading'})\n",
    "best_flights_list = best_flight_heading.find_next('ol', {'class': 'gws-flights-results__result-list'})\n",
    "best_flights = best_flights_list.find_all('li', {'class': 'gws-flights-results__result-item'})\n",
    "\n",
    "# Iterate through each flight to collect time, duration, price, and type (round trip or not)\n",
    "flight_data = pd.DataFrame(columns=['time', 'duration', 'price'])\n",
    "for flight in best_flights:\n",
    "    times = flight.find('div', {'class': 'gws-flights-results__times'}).text\n",
    "    durations = flight.find('div', {'class': 'gws-flights-results__duration'}).text\n",
    "    prices = flight.find('div', {'class': 'gws-flights-results__price'}).text\n",
    "    res = pd.DataFrame({'time': [times], 'duration': [durations], 'price': [prices]})\n",
    "    flight_data = flight_data.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wanderu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wanderu(url):\n",
    "\n",
    "    driver = webdriver.Chrome('/Users/lucy/Documents/Research/chromedriver')\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(0, 200)\") \n",
    "    driver.find_element_by_class_name('closeButton-PleSU').click()\n",
    "    checkboxes = driver.find_elements_by_id('f996b5217258d2bbce3d56aed74be479dcad59a70a093673f6720b13327976ae-span')\n",
    "    checkboxes[1].click()\n",
    "    if len(checkboxes) > 3:\n",
    "        checkboxes[3].click()\n",
    "\n",
    "    driver.find_element_by_id('directOnly-span').click()\n",
    "    driver.find_element_by_id('allowNearby-span').click()\n",
    "    \n",
    "    see_more = True\n",
    "    while see_more:\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, '//button[text()=\"See more\"]').click()\n",
    "        except NoSuchElementException:\n",
    "            see_more = False\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "    \n",
    "    best_buses = soup.find_all('div', {'class': 'searchResult-3dUQ8'})\n",
    "    \n",
    "    bus_data = pd.DataFrame(columns=['depart', 'arrive', 'duration', 'price', 'carrier'])\n",
    "    for bus in best_buses:\n",
    "        depart = bus.find('div', {'aria-label': 'depart'}).text\n",
    "        arrive = bus.find('div', {'aria-label': 'arrive'}).text\n",
    "        duration = bus.find('span',{'aria-label': 'Duration'}).text\n",
    "        price = bus.find('span',{'aria-label': 'Price'}).text\n",
    "        carrier = bus.find('div', {'class': 'carrierName-3UUEV'}).text\n",
    "        res = pd.DataFrame({'depart': [depart], 'arrive': [arrive], 'duration': [duration],\n",
    "                            'price': [price], 'carrier': [carrier]})\n",
    "        bus_data = bus_data.append(res)\n",
    "    \n",
    "    return bus_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 0: 10/17-10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/Boston%2C%20MA%2C%20USA/2019-10-17/?cur=USD&dpid=ChIJGzE9DS1l44kRoOhiASS_fHg&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-17-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'Boston'\n",
    "bus_train.to_csv('data/boston/bus_train_10-17-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Boston%2C%20MA%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-10-20/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJGzE9DS1l44kRoOhiASS_fHg')\n",
    "bus_train['date'] = '10-20-2019'\n",
    "bus_train['origination'] = 'Boston'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/boston/bus_train_10-20-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 1: 10/24-10/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/Boston%2C%20MA%2C%20USA/2019-10-24/?cur=USD&dpid=ChIJGzE9DS1l44kRoOhiASS_fHg&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-24-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'Boston'\n",
    "bus_train.to_csv('data/boston/bus_train_10-24-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Boston%2C%20MA%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-10-27/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJGzE9DS1l44kRoOhiASS_fHg')\n",
    "bus_train['date'] = '10-27-2019'\n",
    "bus_train['origination'] = 'Boston'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/boston/bus_train_10-27-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 2: 10/31-11/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/Boston%2C%20MA%2C%20USA/2019-10-31/?cur=USD&dpid=ChIJGzE9DS1l44kRoOhiASS_fHg&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-31-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'Boston'\n",
    "bus_train.to_csv('data/boston/bus_train_10-31-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Boston%2C%20MA%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-11-03/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJGzE9DS1l44kRoOhiASS_fHg')\n",
    "bus_train['date'] = '11-03-2019'\n",
    "bus_train['origination'] = 'Boston'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/boston/bus_train_11-03-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 0: 10/17-10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/New%20York%2C%20NY%2C%20USA/2019-10-17/?cur=USD&dpid=ChIJOwg_06VPwokRYv534QaPC8g&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-17-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'NYC'\n",
    "bus_train.to_csv('data/nyc/bus_train_10-17-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/New%20York%2C%20NY%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-10-20/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJOwg_06VPwokRYv534QaPC8g')\n",
    "bus_train['date'] = '10-20-2019'\n",
    "bus_train['origination'] = 'NYC'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/nyc/bus_train_10-20-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 1: 10/24-10/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/New%20York%2C%20NY%2C%20USA/2019-10-24/?cur=USD&dpid=ChIJOwg_06VPwokRYv534QaPC8g&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-24-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'NYC'\n",
    "bus_train.to_csv('data/nyc/bus_train_10-24-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/New%20York%2C%20NY%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-10-27/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJOwg_06VPwokRYv534QaPC8g')\n",
    "bus_train['date'] = '10-27-2019'\n",
    "bus_train['origination'] = 'NYC'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/nyc/bus_train_10-27-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 2: 10/31-11/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/New%20York%2C%20NY%2C%20USA/2019-10-31/?cur=USD&dpid=ChIJOwg_06VPwokRYv534QaPC8g&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-31-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'NYC'\n",
    "bus_train.to_csv('data/nyc/bus_train_10-31-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/New%20York%2C%20NY%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-11-03/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJOwg_06VPwokRYv534QaPC8g')\n",
    "bus_train['date'] = '11-03-2019'\n",
    "bus_train['origination'] = 'NYC'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/nyc/bus_train_11-03-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 0: 10/17-10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/Washington%2C%20DC%2C%20USA/2019-10-17/?cur=USD&dpid=ChIJW-T2Wt7Gt4kRKl2I1CJFUsI&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-17-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'DC'\n",
    "bus_train.to_csv('data/dc/bus_train_10-17-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Washington%2C%20DC%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-10-20/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJW-T2Wt7Gt4kRKl2I1CJFUsI')\n",
    "bus_train['date'] = '10-20-2019'\n",
    "bus_train['origination'] = 'DC'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/dc/bus_train_10-20-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 1: 10/24-10/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/Washington%2C%20DC%2C%20USA/2019-10-24/?cur=USD&dpid=ChIJW-T2Wt7Gt4kRKl2I1CJFUsI&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-24-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'DC'\n",
    "bus_train.to_csv('data/dc/bus_train_10-24-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Washington%2C%20DC%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-10-27/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJW-T2Wt7Gt4kRKl2I1CJFUsI')\n",
    "bus_train['date'] = '10-27-2019'\n",
    "bus_train['origination'] = 'DC'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/dc/bus_train_10-27-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend 2: 10/31-11/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Philadelphia%2C%20PA%2C%20USA/Washington%2C%20DC%2C%20USA/2019-10-31/?cur=USD&dpid=ChIJW-T2Wt7Gt4kRKl2I1CJFUsI&opid=ChIJ60u11Ni3xokRwVg-jNgU9Yk')\n",
    "bus_train['date'] = '10-31-2019'\n",
    "bus_train['origination'] = 'Philadelphia'\n",
    "bus_train['destination'] = 'DC'\n",
    "bus_train.to_csv('data/dc/bus_train_10-31-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = scrape_wanderu('https://www.wanderu.com/en-us/depart/Washington%2C%20DC%2C%20USA/Philadelphia%2C%20PA%2C%20USA/2019-11-03/?cur=USD&dpid=ChIJ60u11Ni3xokRwVg-jNgU9Yk&opid=ChIJW-T2Wt7Gt4kRKl2I1CJFUsI')\n",
    "bus_train['date'] = '11-03-2019'\n",
    "bus_train['origination'] = 'DC'\n",
    "bus_train['destination'] = 'Philadelphia'\n",
    "bus_train.to_csv('data/dc/bus_train_11-03-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
